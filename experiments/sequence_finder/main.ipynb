{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/data.json\") as json_file:\n",
    "    json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the JSON data to a DataFrame\n",
    "df = pd.json_normalize(json_data)\n",
    "\n",
    "# Extract necessary columns\n",
    "df['frame'] = df['payload.frame']\n",
    "df['video_id'] = df['payload.video_id']\n",
    "\n",
    "# Sort by frame number\n",
    "df = df.sort_values(by='frame').reset_index(drop=True)\n",
    "\n",
    "# Function to find sequences with the same video_id\n",
    "def find_sequences(df, min_length=2):\n",
    "    sequences = []\n",
    "    current_sequence = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if not current_sequence:\n",
    "            current_sequence.append(row)\n",
    "        else:\n",
    "            if row['video_id'] == current_sequence[-1]['video_id']:\n",
    "                current_sequence.append(row)\n",
    "            else:\n",
    "                if len(current_sequence) >= min_length:\n",
    "                    sequences.append(current_sequence)\n",
    "                current_sequence = [row]\n",
    "    \n",
    "    if len(current_sequence) >= min_length:\n",
    "        sequences.append(current_sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Find sequences with a minimum length threshold\n",
    "min_length = 3000\n",
    "sequences = find_sequences(df, min_length)\n",
    "\n",
    "# Print the sequences\n",
    "for seq in sequences:\n",
    "    print(f\"Sequence with video_id {seq[0]['video_id']}:\")\n",
    "    for item in seq:\n",
    "        print(f\"  Frame: {item['frame']}, ID: {item['id']}, Score: {item['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the JSON data to a DataFrame\n",
    "df = pd.json_normalize(json_data)\n",
    "\n",
    "# Extract necessary columns\n",
    "df['frame'] = df['payload.frame']\n",
    "df['video_id'] = df['payload.video_id']\n",
    "\n",
    "# Sort by frame number\n",
    "df = df.sort_values(by='frame').reset_index(drop=True)\n",
    "\n",
    "# Apply a window function to identify sequences\n",
    "df['prev_video_id'] = df['video_id'].shift(1)\n",
    "df['new_sequence'] = df['video_id'] != df['prev_video_id']\n",
    "\n",
    "# Create a sequence identifier\n",
    "df['sequence_id'] = df['new_sequence'].cumsum()\n",
    "\n",
    "# Count the length of each sequence\n",
    "df['sequence_length'] = df.groupby('sequence_id')['sequence_id'].transform('size')\n",
    "\n",
    "# Filter sequences by minimum length\n",
    "min_length = 100\n",
    "filtered_df = df[df['sequence_length'] >= min_length]\n",
    "\n",
    "# Get the unique sequences that meet the minimum length threshold\n",
    "sequences = filtered_df.groupby('sequence_id').apply(lambda x: x.to_dict(orient='records'))\n",
    "\n",
    "# Print the sequences\n",
    "for seq_id, seq in sequences.items():\n",
    "    print(f\"Sequence ID {seq_id} with video_id {seq[0]['video_id']}:\")\n",
    "    for item in seq:\n",
    "        print(f\"  Frame: {item['frame']}, ID: {item['id']}, Score: {item['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the JSON data to a DataFrame\n",
    "df = pd.json_normalize(json_data)\n",
    "\n",
    "# Extract necessary columns\n",
    "df['frame'] = df['payload.frame']\n",
    "df['video_id'] = df['payload.video_id']\n",
    "\n",
    "# Sort by frame number\n",
    "df = df.sort_values(by='frame').reset_index(drop=True)\n",
    "\n",
    "# Smooth filter function to ignore up to n frames between sequences\n",
    "def smooth_sequences(df, max_skip=1, min_length=2):\n",
    "    sequences = []\n",
    "    current_sequence = []\n",
    "    skip_count = 0\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if not current_sequence:\n",
    "            current_sequence.append(row.to_dict())\n",
    "        else:\n",
    "            if row['video_id'] == current_sequence[-1]['video_id']:\n",
    "                current_sequence.append(row.to_dict())\n",
    "                skip_count = 0\n",
    "            else:\n",
    "                if skip_count < max_skip:\n",
    "                    skip_count += 1\n",
    "                    current_sequence.append(row.to_dict())\n",
    "                else:\n",
    "                    filtered_sequence = [seq for seq in current_sequence if seq['video_id'] == current_sequence[0]['video_id']]\n",
    "                    if len(filtered_sequence) >= min_length:\n",
    "                        sequences.append(filtered_sequence)\n",
    "                    current_sequence = [row.to_dict()]\n",
    "                    skip_count = 0\n",
    "    \n",
    "    # Final check for the last sequence\n",
    "    filtered_sequence = [seq for seq in current_sequence if seq['video_id'] == current_sequence[0]['video_id']]\n",
    "    if len(filtered_sequence) >= min_length:\n",
    "        sequences.append(filtered_sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Find sequences with a smooth filter\n",
    "max_skip = 10\n",
    "min_length = 100\n",
    "sequences = smooth_sequences(df, max_skip, min_length)\n",
    "\n",
    "# Calculate mean score for each sequence\n",
    "def calculate_mean_score(sequence):\n",
    "    mean_score = sum(item['score'] for item in sequence) / len(sequence)\n",
    "    return mean_score\n",
    "\n",
    "# Print the sequences with mean scores\n",
    "for seq in sequences:\n",
    "    mean_score = calculate_mean_score(seq)\n",
    "    print(f\"Sequence with video_id {seq[0]['video_id']}, Mean Score: {mean_score:.6f}:\")\n",
    "    for item in seq:\n",
    "        print(f\"  Frame: {item['frame']}, ID: {item['id']}, Score: {item['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the JSON data to a DataFrame\n",
    "df = pd.json_normalize(json_data)\n",
    "df[\"query_video_frame\"] = list(range(len(df)))\n",
    "\n",
    "# Extract necessary columns\n",
    "df['frame'] = df['payload.frame']\n",
    "df['video_id'] = df['payload.video_id']\n",
    "\n",
    "# Sort by frame number\n",
    "df = df.sort_values(by='query_video_frame').reset_index(drop=True)\n",
    "\n",
    "# Smooth filter function to ignore up to n frames between sequences\n",
    "def smooth_sequences(df, max_skip=1, min_length=2):\n",
    "    sequences = []\n",
    "    current_sequence = []\n",
    "    skip_count = 0\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if not current_sequence:\n",
    "            current_sequence.append(row.to_dict())\n",
    "        else:\n",
    "            if row['video_id'] == current_sequence[-1]['video_id']:\n",
    "                current_sequence.append(row.to_dict())\n",
    "                skip_count = 0\n",
    "            else:\n",
    "                if skip_count < max_skip:\n",
    "                    skip_count += 1\n",
    "                    current_sequence.append(row.to_dict())\n",
    "                else:\n",
    "                    filtered_sequence = [seq for seq in current_sequence if seq['video_id'] == current_sequence[0]['video_id']]\n",
    "                    if len(filtered_sequence) >= min_length:\n",
    "                        sequences.append(filtered_sequence)\n",
    "                    current_sequence = [row.to_dict()]\n",
    "                    skip_count = 0\n",
    "    \n",
    "    # Final check for the last sequence\n",
    "    filtered_sequence = [seq for seq in current_sequence if seq['video_id'] == current_sequence[0]['video_id']]\n",
    "    if len(filtered_sequence) >= min_length:\n",
    "        sequences.append(filtered_sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Find sequences with a smooth filter\n",
    "max_skip = 10\n",
    "min_length = 100\n",
    "sequences = smooth_sequences(df, max_skip, min_length)\n",
    "\n",
    "# Calculate mean score for each sequence\n",
    "def calculate_mean_score(sequence):\n",
    "    mean_score = sum(item['score'] for item in sequence) / len(sequence)\n",
    "    return mean_score\n",
    "\n",
    "# Frame rate\n",
    "frame_rate = 10  # frames per second\n",
    "\n",
    "# Function to convert frame number to time\n",
    "def frame_to_time(frame, frame_rate):\n",
    "    return timedelta(seconds=frame/frame_rate)\n",
    "\n",
    "# Print the sequences with mean scores and time frames\n",
    "for seq in sequences:\n",
    "    mean_score = calculate_mean_score(seq)\n",
    "    start_frame = seq[0]['frame']\n",
    "    end_frame = seq[-1]['frame']\n",
    "    start_time = frame_to_time(start_frame, frame_rate)\n",
    "    end_time = frame_to_time(end_frame, frame_rate)\n",
    "    \n",
    "    print(f\"Sequence with video_id {seq[0]['video_id']}, Mean Score: {mean_score:.6f}:\")\n",
    "    print(f\"  Target Time: {start_time} - {end_time}\")\n",
    "    \n",
    "    for item in seq:\n",
    "        item_start_time = frame_to_time(item['frame'], frame_rate)\n",
    "        print(f\"    Frame: {item['frame']}, Initial frame: {item['query_video_frame']}, Score: {item['score']}, Time: {item_start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mean_score(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class MatchingData(BaseModel):\n",
    "    query_start_frame: int\n",
    "    query_end_frame: int\n",
    "    query_start_time: timedelta\n",
    "    query_end_time: timedelta\n",
    "\n",
    "    match_video_id: str\n",
    "    match_start_frame: int\n",
    "    match_end_frame: int\n",
    "    match_start_time: timedelta\n",
    "    match_end_time: timedelta\n",
    "\n",
    "    similarity_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score = calculate_mean_score(seq)\n",
    "\n",
    "query_start_frame = seq[0]['query_video_frame']\n",
    "query_end_frame = seq[-1]['query_video_frame']\n",
    "query_start_time = frame_to_time(query_start_frame, frame_rate)\n",
    "query_end_time = frame_to_time(query_end_frame, frame_rate)\n",
    "\n",
    "match_start_frame = seq[0]['frame']\n",
    "match_end_frame = seq[-1]['frame']\n",
    "match_start_time = frame_to_time(match_start_frame, frame_rate)\n",
    "match_end_time = frame_to_time(match_end_frame, frame_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_metadata = MatchingData(\n",
    "                                query_start_frame=query_start_frame,\n",
    "                                query_end_frame=query_end_frame,\n",
    "                                query_start_time=query_start_time,\n",
    "                                query_end_time=query_end_time,\n",
    "\n",
    "                                match_video_id=seq[0][\"video_id\"],\n",
    "                                match_start_frame=match_start_frame,\n",
    "                                match_end_frame=match_end_frame,\n",
    "                                match_start_time=match_start_time,\n",
    "                                match_end_time=match_end_time,\n",
    "\n",
    "                                similarity_score=mean_score\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_metadata.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
