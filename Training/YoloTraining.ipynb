{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    random_frame_number = random.randint(0, frame_count - 1)\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def resize_frame(frame):\n",
    "    x, y, _ = frame.shape\n",
    "    scale = random.uniform(0.3, 0.6)\n",
    "    return cv2.resize(frame, (int(y*scale), int(x*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def insert_frame(base_frame, insert_frame):\n",
    "    h, w, _ = base_frame.shape\n",
    "    ih, iw, _ = insert_frame.shape\n",
    "\n",
    "    x = random.randint(0, w - iw)\n",
    "    y = random.randint(0, h - ih)\n",
    "    \n",
    "    combined_frame = base_frame.copy()\n",
    "    combined_frame[y:y+ih, x:x+iw] = insert_frame\n",
    "    \n",
    "    bbox = (x, y, iw, ih)\n",
    "    \n",
    "    return combined_frame, bbox\n",
    "\n",
    "def save_image_and_annotation(image, bbox, output_image, output_label, index):\n",
    "    image_path = os.path.join(output_image, f'image_{index}.jpg')\n",
    "    annotation_path = os.path.join(output_label, f'image_{index}.txt')\n",
    "    \n",
    "    cv2.imwrite(image_path, image)\n",
    "    \n",
    "    if bbox is None:\n",
    "        open(annotation_path, 'w').close()\n",
    "    else:\n",
    "        x, y, w, h = bbox\n",
    "        img_h, img_w, _ = image.shape\n",
    "        center_x = (x + w / 2) / img_w\n",
    "        center_y = (y + h / 2) / img_h\n",
    "        width = w / img_w\n",
    "        height = h / img_h\n",
    "    \n",
    "        class_id = 0\n",
    "        \n",
    "        with open(annotation_path, 'w') as f:\n",
    "            f.write(f\"{class_id} {center_x} {center_y} {width} {height}\\n\")\n",
    "\n",
    "def process_videos(input_folder, output_folder, dataset_size, proc_chance):\n",
    "    \n",
    "    video_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
    "    \n",
    "    labels = os.path.join(output_folder, \"labels\")\n",
    "    images = os.path.join(output_folder, \"images\")\n",
    "\n",
    "    os.makedirs(labels)\n",
    "    os.makedirs(images)\n",
    "\n",
    "    for i in tqdm(range(dataset_size)):\n",
    "\n",
    "        video_file1, video_file2 = random.sample(video_files, 2)\n",
    "        \n",
    "        frame1 = get_random_frame(video_file1)\n",
    "\n",
    "        if random.random() < proc_chance:\n",
    "\n",
    "            save_image_and_annotation(frame1, None, images, labels, i)\n",
    "        else:\n",
    "        \n",
    "            frame2 = get_random_frame(video_file2)\n",
    "            \n",
    "            resized_frame2 = resize_frame(frame2)\n",
    "\n",
    "            combined_frame, bbox = insert_frame(frame1, resized_frame2)\n",
    "\n",
    "            save_image_and_annotation(combined_frame, bbox, images, labels, i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input_folder, output_folder, train_size, val_size, test_size, proc_chance=0.5):\n",
    "    train = os.path.join(output_folder, \"train\")\n",
    "    val = os.path.join(output_folder, \"valid\")\n",
    "    test = os.path.join(output_folder, \"test\")\n",
    "\n",
    "    process_videos(input_folder, train, train_size, proc_chance)\n",
    "    process_videos(input_folder, val, val_size, proc_chance)\n",
    "    process_videos(input_folder, test, test_size, proc_chance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"\"\n",
    "OUTPUT = \"\"\n",
    "create_dataset(INPUT, OUTPUT, 20000, 3000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "results = model.train(data=os.path.join(OUTPUT, \"data.yaml\"), epochs=200, device=\"cpu\")\n",
    "results = model.val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "new_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
